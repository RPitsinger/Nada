{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "## Physics-Informed Neural Network for 1D Heat Equation in PyTorch\n",
    "\n",
    "This notebook implements a Physics-Informed Neural Network (PINN) to solve the 1D heat equation using PyTorch.\n",
    "\n",
    "### Problem Statement\n",
    "\n",
    "We want to solve the 1D heat equation:\n",
    "\n",
    "$$ \\frac{\\partial u}{\\partial t}(x,t) = \\lambda \\frac{\\partial^2 u}{\\partial x^2}(x,t)$$\n",
    "\n",
    "for $x\\in [0,L]$ and $t>0$ with:\n",
    "\n",
    "**Initial condition:**\n",
    "$$ u(x,0) = \\sin(\\pi x/L) $$\n",
    "\n",
    "**Boundary conditions:**\n",
    "$$ u(0,t) = u(L,t) = 0$$\n",
    "\n",
    "The physics-informed neural network approach minimizes the residual of the PDE:\n",
    "\n",
    "$$ D_u(x,t) = \\frac{\\partial u}{\\partial t} - \\lambda \\frac{\\partial^2 u}{\\partial x^2} = 0 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports-header",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyDOE import lhs\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(1234)\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "params-header",
   "metadata": {},
   "source": [
    "## Problem Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "params",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain parameters\n",
    "L = 1.0          # Length of spatial domain\n",
    "T_max = 1.0      # Maximum time\n",
    "lam = 0.01       # Thermal diffusivity (lambda)\n",
    "\n",
    "# Domain bounds\n",
    "x_min, x_max = 0.0, L\n",
    "t_min, t_max = 0.0, T_max\n",
    "\n",
    "print(f'Spatial domain: [{x_min}, {x_max}]')\n",
    "print(f'Time domain: [{t_min}, {t_max}]')\n",
    "print(f'Thermal diffusivity: {lam}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "network-header",
   "metadata": {},
   "source": [
    "## Neural Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "network",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN(nn.Module):\n",
    "    \"\"\"Physics-Informed Neural Network for the Heat Equation\"\"\"\n",
    "    \n",
    "    def __init__(self, layers):\n",
    "        super(PINN, self).__init__()\n",
    "        \n",
    "        # Network architecture\n",
    "        self.layers = layers\n",
    "        self.num_layers = len(layers)\n",
    "        \n",
    "        # Create network layers\n",
    "        self.linears = nn.ModuleList([\n",
    "            nn.Linear(layers[i], layers[i+1]) for i in range(self.num_layers - 1)\n",
    "        ])\n",
    "        \n",
    "        # Initialize weights using Xavier initialization\n",
    "        for i in range(self.num_layers - 1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight)\n",
    "            nn.init.zeros_(self.linears[i].bias)\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        \"\"\"Forward pass through the network\n",
    "        \n",
    "        Args:\n",
    "            x: spatial coordinates (batch_size, 1)\n",
    "            t: temporal coordinates (batch_size, 1)\n",
    "        \n",
    "        Returns:\n",
    "            u: predicted temperature (batch_size, 1)\n",
    "        \"\"\"\n",
    "        # Concatenate inputs\n",
    "        inputs = torch.cat([x, t], dim=1)\n",
    "        \n",
    "        # Forward pass through hidden layers with tanh activation\n",
    "        h = inputs\n",
    "        for i in range(self.num_layers - 2):\n",
    "            h = torch.tanh(self.linears[i](h))\n",
    "        \n",
    "        # Output layer (linear)\n",
    "        u = self.linears[-1](h)\n",
    "        return u\n",
    "    \n",
    "    def pde_residual(self, x, t, lam):\n",
    "        \"\"\"Compute the PDE residual D_u = u_t - lambda * u_xx\n",
    "        \n",
    "        Args:\n",
    "            x: spatial coordinates\n",
    "            t: temporal coordinates\n",
    "            lam: thermal diffusivity\n",
    "        \n",
    "        Returns:\n",
    "            residual: PDE residual\n",
    "        \"\"\"\n",
    "        # Enable gradient computation\n",
    "        x.requires_grad_(True)\n",
    "        t.requires_grad_(True)\n",
    "        \n",
    "        # Compute u\n",
    "        u = self.forward(x, t)\n",
    "        \n",
    "        # First derivatives\n",
    "        u_t = torch.autograd.grad(\n",
    "            u, t, \n",
    "            grad_outputs=torch.ones_like(u),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        \n",
    "        u_x = torch.autograd.grad(\n",
    "            u, x,\n",
    "            grad_outputs=torch.ones_like(u),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        \n",
    "        # Second derivative\n",
    "        u_xx = torch.autograd.grad(\n",
    "            u_x, x,\n",
    "            grad_outputs=torch.ones_like(u_x),\n",
    "            retain_graph=True,\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        \n",
    "        # PDE residual: u_t - lambda * u_xx = 0\n",
    "        residual = u_t - lam * u_xx\n",
    "        \n",
    "        return residual\n",
    "\n",
    "# Define network architecture\n",
    "layers = [2, 32, 32, 32, 1]  # [input_dim, hidden1, hidden2, hidden3, output_dim]\n",
    "model = PINN(layers).to(device)\n",
    "\n",
    "print(f'Network architecture: {layers}')\n",
    "print(f'Total parameters: {sum(p.numel() for p in model.parameters())}')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-header",
   "metadata": {},
   "source": [
    "## Generate Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of training points\n",
    "N_ic = 100      # Initial condition points\n",
    "N_bc = 100      # Boundary condition points\n",
    "N_pde = 10000   # Collocation points for PDE residual\n",
    "\n",
    "# Initial condition: u(x, 0) = sin(pi * x / L)\n",
    "x_ic = np.random.uniform(x_min, x_max, (N_ic, 1))\n",
    "t_ic = np.zeros((N_ic, 1))\n",
    "u_ic = np.sin(np.pi * x_ic / L)\n",
    "\n",
    "# Boundary condition at x = 0: u(0, t) = 0\n",
    "x_bc1 = np.zeros((N_bc, 1))\n",
    "t_bc1 = np.random.uniform(t_min, t_max, (N_bc, 1))\n",
    "u_bc1 = np.zeros((N_bc, 1))\n",
    "\n",
    "# Boundary condition at x = L: u(L, t) = 0\n",
    "x_bc2 = L * np.ones((N_bc, 1))\n",
    "t_bc2 = np.random.uniform(t_min, t_max, (N_bc, 1))\n",
    "u_bc2 = np.zeros((N_bc, 1))\n",
    "\n",
    "# Combine all initial and boundary conditions\n",
    "x_data = np.vstack([x_ic, x_bc1, x_bc2])\n",
    "t_data = np.vstack([t_ic, t_bc1, t_bc2])\n",
    "u_data = np.vstack([u_ic, u_bc1, u_bc2])\n",
    "\n",
    "# Collocation points for PDE residual (Latin Hypercube Sampling)\n",
    "lb = np.array([x_min, t_min])\n",
    "ub = np.array([x_max, t_max])\n",
    "X_pde = lb + (ub - lb) * lhs(2, N_pde)\n",
    "x_pde = X_pde[:, 0:1]\n",
    "t_pde = X_pde[:, 1:2]\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "x_data_tensor = torch.tensor(x_data, dtype=torch.float32, requires_grad=False).to(device)\n",
    "t_data_tensor = torch.tensor(t_data, dtype=torch.float32, requires_grad=False).to(device)\n",
    "u_data_tensor = torch.tensor(u_data, dtype=torch.float32, requires_grad=False).to(device)\n",
    "\n",
    "x_pde_tensor = torch.tensor(x_pde, dtype=torch.float32, requires_grad=True).to(device)\n",
    "t_pde_tensor = torch.tensor(t_pde, dtype=torch.float32, requires_grad=True).to(device)\n",
    "\n",
    "print(f'Initial condition points: {N_ic}')\n",
    "print(f'Boundary condition points: {2 * N_bc}')\n",
    "print(f'PDE collocation points: {N_pde}')\n",
    "print(f'Total data points: {x_data.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viz-data-header",
   "metadata": {},
   "source": [
    "## Visualize Training Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(t_data, x_data, c='blue', s=10, alpha=0.6, label='IC/BC points')\n",
    "plt.xlabel('t')\n",
    "plt.ylabel('x')\n",
    "plt.title('Initial and Boundary Condition Points')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(t_pde, x_pde, c='red', s=1, alpha=0.3, label='Collocation points')\n",
    "plt.xlabel('t')\n",
    "plt.ylabel('x')\n",
    "plt.title('PDE Collocation Points')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "train-header",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "epochs = 10000\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Loss history\n",
    "loss_history = []\n",
    "loss_data_history = []\n",
    "loss_pde_history = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    # Zero gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Predict u at data points\n",
    "    u_pred = model(x_data_tensor, t_data_tensor)\n",
    "    \n",
    "    # Data loss (MSE for initial and boundary conditions)\n",
    "    loss_data = torch.mean((u_pred - u_data_tensor) ** 2)\n",
    "    \n",
    "    # PDE residual loss\n",
    "    residual = model.pde_residual(x_pde_tensor, t_pde_tensor, lam)\n",
    "    loss_pde = torch.mean(residual ** 2)\n",
    "    \n",
    "    # Total loss\n",
    "    loss = loss_data + loss_pde\n",
    "    \n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Store losses\n",
    "    loss_history.append(loss.item())\n",
    "    loss_data_history.append(loss_data.item())\n",
    "    loss_pde_history.append(loss_pde.item())\n",
    "    \n",
    "    # Print progress\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item():.6f}, '\n",
    "              f'Data Loss: {loss_data.item():.6f}, PDE Loss: {loss_pde.item():.6f}')\n",
    "\n",
    "print('\\nTraining completed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loss-viz-header",
   "metadata": {},
   "source": [
    "## Visualize Training Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loss-viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.semilogy(loss_history, 'b-', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Total Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.semilogy(loss_data_history, 'g-', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Data Loss')\n",
    "plt.title('Data Loss (IC/BC)')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.semilogy(loss_pde_history, 'r-', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('PDE Loss')\n",
    "plt.title('PDE Residual Loss')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "predict-header",
   "metadata": {},
   "source": [
    "## Prediction and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "predict",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a grid for prediction\n",
    "N_x = 256\n",
    "N_t = 100\n",
    "\n",
    "x_test = np.linspace(x_min, x_max, N_x)\n",
    "t_test = np.linspace(t_min, t_max, N_t)\n",
    "X_grid, T_grid = np.meshgrid(x_test, t_test)\n",
    "\n",
    "x_flat = X_grid.flatten()[:, None]\n",
    "t_flat = T_grid.flatten()[:, None]\n",
    "\n",
    "# Convert to tensors\n",
    "x_test_tensor = torch.tensor(x_flat, dtype=torch.float32).to(device)\n",
    "t_test_tensor = torch.tensor(t_flat, dtype=torch.float32).to(device)\n",
    "\n",
    "# Predict\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    u_pred = model(x_test_tensor, t_test_tensor)\n",
    "\n",
    "# Reshape for plotting\n",
    "u_pred_grid = u_pred.cpu().numpy().reshape(N_t, N_x)\n",
    "\n",
    "print('Prediction completed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analytical-header",
   "metadata": {},
   "source": [
    "## Analytical Solution for Comparison\n",
    "\n",
    "The analytical solution for the heat equation with the given initial and boundary conditions is:\n",
    "\n",
    "$$ u(x,t) = \\sin(\\pi x/L) \\exp(-\\lambda (\\pi/L)^2 t) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analytical",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analytical solution\n",
    "u_analytical = np.sin(np.pi * X_grid / L) * np.exp(-lam * (np.pi / L) ** 2 * T_grid)\n",
    "\n",
    "# Compute error\n",
    "error = np.linalg.norm(u_pred_grid - u_analytical, 2) / np.linalg.norm(u_analytical, 2)\n",
    "print(f'Relative L2 error: {error:.6e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final-viz-header",
   "metadata": {},
   "source": [
    "## Compare PINN Prediction with Analytical Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# PINN prediction\n",
    "ax = axes[0, 0]\n",
    "im1 = ax.imshow(u_pred_grid.T, interpolation='nearest', cmap='hot',\n",
    "                extent=[t_min, t_max, x_min, x_max],\n",
    "                origin='lower', aspect='auto', vmin=-1, vmax=1)\n",
    "ax.set_xlabel('t')\n",
    "ax.set_ylabel('x')\n",
    "ax.set_title('PINN Prediction')\n",
    "plt.colorbar(im1, ax=ax)\n",
    "\n",
    "# Plot training data points\n",
    "ax.scatter(t_data, x_data, c='cyan', s=2, alpha=0.5, label='Training points')\n",
    "ax.legend(loc='upper right')\n",
    "\n",
    "# Analytical solution\n",
    "ax = axes[0, 1]\n",
    "im2 = ax.imshow(u_analytical.T, interpolation='nearest', cmap='hot',\n",
    "                extent=[t_min, t_max, x_min, x_max],\n",
    "                origin='lower', aspect='auto', vmin=-1, vmax=1)\n",
    "ax.set_xlabel('t')\n",
    "ax.set_ylabel('x')\n",
    "ax.set_title('Analytical Solution')\n",
    "plt.colorbar(im2, ax=ax)\n",
    "\n",
    "# Absolute error\n",
    "ax = axes[1, 0]\n",
    "error_abs = np.abs(u_pred_grid - u_analytical)\n",
    "im3 = ax.imshow(error_abs.T, interpolation='nearest', cmap='viridis',\n",
    "                extent=[t_min, t_max, x_min, x_max],\n",
    "                origin='lower', aspect='auto')\n",
    "ax.set_xlabel('t')\n",
    "ax.set_ylabel('x')\n",
    "ax.set_title('Absolute Error')\n",
    "plt.colorbar(im3, ax=ax)\n",
    "\n",
    "# Temporal slices at different times\n",
    "ax = axes[1, 1]\n",
    "time_indices = [0, N_t // 4, N_t // 2, 3 * N_t // 4, N_t - 1]\n",
    "colors = ['blue', 'green', 'orange', 'red', 'purple']\n",
    "\n",
    "for idx, color in zip(time_indices, colors):\n",
    "    t_val = t_test[idx]\n",
    "    ax.plot(x_test, u_pred_grid[idx, :], '--', color=color, \n",
    "            linewidth=2, label=f'PINN t={t_val:.2f}')\n",
    "    ax.plot(x_test, u_analytical[idx, :], '-', color=color, \n",
    "            linewidth=1, alpha=0.7, label=f'Exact t={t_val:.2f}')\n",
    "\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('u(x, t)')\n",
    "ax.set_title('Spatial Profiles at Different Times')\n",
    "ax.legend(fontsize=8, ncol=2)\n",
    "ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'\\nRelative L2 error: {error:.6e}')\n",
    "print(f'Maximum absolute error: {np.max(error_abs):.6e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "residual-header",
   "metadata": {},
   "source": [
    "## Visualize PDE Residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residual",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute PDE residual on the test grid\n",
    "x_test_tensor_grad = torch.tensor(x_flat, dtype=torch.float32, requires_grad=True).to(device)\n",
    "t_test_tensor_grad = torch.tensor(t_flat, dtype=torch.float32, requires_grad=True).to(device)\n",
    "\n",
    "residual_test = model.pde_residual(x_test_tensor_grad, t_test_tensor_grad, lam)\n",
    "residual_grid = residual_test.detach().cpu().numpy().reshape(N_t, N_x)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "im = plt.imshow(residual_grid.T ** 2, interpolation='nearest', cmap='viridis',\n",
    "                extent=[t_min, t_max, x_min, x_max],\n",
    "                origin='lower', aspect='auto')\n",
    "plt.colorbar(im, label='Squared Residual')\n",
    "plt.xlabel('t')\n",
    "plt.ylabel('x')\n",
    "plt.title('PDE ResidualÂ² (Should be close to 0)')\n",
    "plt.show()\n",
    "\n",
    "print(f'Mean squared residual: {np.mean(residual_grid ** 2):.6e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animation-header",
   "metadata": {},
   "source": [
    "## Create Animation of the Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Create animation\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "line_pinn, = ax.plot([], [], 'b-', linewidth=2, label='PINN')\n",
    "line_exact, = ax.plot([], [], 'r--', linewidth=2, label='Analytical')\n",
    "\n",
    "ax.set_xlim(x_min, x_max)\n",
    "ax.set_ylim(-1.1, 1.1)\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('u(x, t)')\n",
    "ax.set_title('1D Heat Equation Solution')\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "\n",
    "time_text = ax.text(0.02, 0.95, '', transform=ax.transAxes, fontsize=12,\n",
    "                    verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "def init():\n",
    "    line_pinn.set_data([], [])\n",
    "    line_exact.set_data([], [])\n",
    "    time_text.set_text('')\n",
    "    return line_pinn, line_exact, time_text\n",
    "\n",
    "def animate(frame):\n",
    "    line_pinn.set_data(x_test, u_pred_grid[frame, :])\n",
    "    line_exact.set_data(x_test, u_analytical[frame, :])\n",
    "    time_text.set_text(f't = {t_test[frame]:.3f}')\n",
    "    return line_pinn, line_exact, time_text\n",
    "\n",
    "ani = FuncAnimation(fig, animate, init_func=init, frames=N_t, \n",
    "                   interval=50, blit=True, repeat=True)\n",
    "\n",
    "plt.close()  # Prevent duplicate display\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates how to solve the 1D heat equation using a Physics-Informed Neural Network (PINN) implemented in PyTorch. The key features are:\n",
    "\n",
    "1. **Neural Network**: A fully connected network with tanh activation functions\n",
    "2. **Physics-Informed Loss**: Combination of data loss (initial/boundary conditions) and PDE residual loss\n",
    "3. **Automatic Differentiation**: PyTorch's autograd computes the required derivatives for the PDE\n",
    "4. **Training**: Adam optimizer minimizes the combined loss\n",
    "5. **Validation**: Comparison with analytical solution shows the accuracy of the PINN approach\n",
    "\n",
    "The PINN successfully learns the solution to the heat equation without requiring dense sampling of the solution in the interior of the domain, demonstrating the power of incorporating physical laws directly into the learning process."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
